---
title: Search
description: "Add natural language search to your app using AI embeddings"
"og:title": "Search - Modus"
---

By leveraging embeddings, developers can enable semantic and similarity-based
searches, improving the relevance of search results within their applications.

Vector search is a powerful technique that transforms data (like text, images,
or audio) into numerical representations called embeddings. These embeddings
capture the semantic meaning of the content in a multi-dimensional space, where
similar items are positioned closer together. When performing a search, the
query is also converted into an embedding, and the system finds items whose
embeddings are closest to the query embedding. This approach offers significant
benefits over traditional keyword-based search, including improved relevance by
capturing context and semantics, enhanced precision by understanding user
intent, and the ability to handle complex queries with higher accuracy. Vector
search is particularly effective for applications like semantic search,
recommendation systems, and retrieval augmented generation (RAG), optimizing
both efficiency and accuracy in finding and retrieving data based on meaningful
similarity rather than exact matches.

For example, with natural language similarity, if you search for a product
description like 'sleek red sports car', the search method returns similar
product descriptions such as "luxury sports car in red" or 'high-speed car with
sleek design'.

## Options for implementing natural language search with Modus

Options for adding natural language search to your Modus app include:

1. [**Using Dgraph's vector search functionality**](#natural-language-search-with-dgraph-and-modus)
   Take advantage of Dgraph's HNSW index-backed vector search for highly
   scalable natural language search. This approach can also be used for more
   sophisticated retrieval approaches that combine vector search and graph
   traversals such as GraphRAG patterns.
2. [**Using Modus's built-in Collection data structure**](#natural-language-search-with-modus-collections)
   Modus Collections include functionality to automatically generate embeddings
   for new data and are good for medium-sized data.

## Natural language search with Dgraph and Modus

The steps to implement natural language search with Dgraph include defining the
Dgraph connection in your Modus app manifest, selecting and configuring an
embedding model, declaring a vector index in the Dgraph DQL schema, and using
the `similar_to` DQL function to search for similar text in vector space.

The system stores, retrieves, updates, and deletes product information while
enabling semantic similarity searches using text embeddings generated via
machine learning models.

### Declare Dgraph connection and Hypermode embedding model

First, update the Modus app manifest file `modus.json` to define the connection
to your Dgraph instance and the embedding model that will be used to

```json
{
  "$schema": "https://schema.hypermode.com/modus.json",
  "endpoints": {
    "default": {
      "type": "graphql",
      "path": "/graphql",
      "auth": "bearer-token"
    }
  },
  "models": {
    "minilm": {
      "sourceModel": "sentence-transformers/all-MiniLM-L6-v2",
      "connection": "hypermode",
      "provider": "hugging-face"
    }
  },
  "connections": {
    "dgraph-grpc": {
      "type": "dgraph",
      "grpcTarget": "localhost:9080"
    }
  }
}
```

<Note>
  In order to use Hypermode hosted models in the local Modus development
  environment you'll need to use the `hyp` CLI to connect your local environment
  with your Hypermode account. See the [Using Hypermode-hosted
  models](run-locally#using-hypermode-hosted-models) docs page for more
  information.
</Note>

### Data modeling

Define your data model using classes with decorators for automatic
serialization/deserialization. The @json decorator enables JSON serialization,
while @alias maps property names to Dgraph-friendly formats:

```ts
@json
export class Product {
  @alias("Product.id")
  id!: string

  @alias("Product.title")
  title: string = ""

  @alias("Product.description")
  description: string = ""

  @alias("Product.category")
  @omitnull()
  category: Category | null = null
}

@json
export class Category {
  @alias("Category.name")
  name: string = ""
}
```

### Embedding Integration

Create an embedding function that uses a transformer model (like minilm) to
convert product descriptions and search queries into vectors:

```ts
import { models } from "@hypermode/modus-sdk-as"
import { EmbeddingsModel } from "@hypermode/modus-sdk-as/models/experimental/embeddings"

const EMBEDDING_MODEL = "minilm"export

function embedText(content: string[]): f32[][] {
const model = models.getModel<EmbeddingsModel>(EMBEDDING_MODEL)
const input = model.createInput(content)
const output = model.invoke(input)
return output.predictions
}
```

### Dgraph `similar_to` query function

Create a Modus function that

Create utility functions to interact with Dgraph, including functions to inject
UIDs into JSON payloads, retrieve entities by properties, delete node
predicates, and perform similarity searches:

```ts
export function searchBySimilarity<T>(
  connection: string,
  embedding: f32[],
  predicate: string,
  body: string,
  topK: i32,
): T[] {
  const query = new dgraph.Query(`
    query search($vector: float32vector) {
        var(func: similar_to(${predicate},${topK},$vector))  {    
            vemb as Product.embedding 
            dist as math((vemb - $vector) dot (vemb - $vector))
            score as math(1 - (dist / 2.0))
        } 
        
        list(func:uid(score),orderdesc:val(score))  @filter(gt(val(score),0.25)){ 
            ${body}
        }
    }`).withVariable("$vector", embedding)

  const response = dgraph.executeQuery(connection, query)
  console.log(response.Json)
  return JSON.parse<ListOf<T>>(response.Json).list
}

/**
 * Search products by similarity to a given text
 */
export function searchProducts(search: string): Product[] {
  const embedding = embedText([search])[0]
  const topK = 3
  const body = `
    Product.id
    Product.description
    Product.title
    Product.category {
      Category.name
    }
  `
  return searchBySimilarity<Product>(
    DGRAPH_CONNECTION,
    embedding,
    "Product.embedding",
    body,
    topK,
  )
}
```

### Define Modus mutation functions

Implement

```ts
/**
 * Add or update a new product to the database
 */
export function upsertProduct(product: Product): Map<string, string> | null {
  let payload = buildProductMutationJson(DGRAPH_CONNECTION, product)

  const embedding = embedText([product.description])[0]
  payload = addEmbeddingToJson(payload, "Product.embedding", embedding)

  const mutation = new dgraph.Mutation(payload)
  const response = dgraph.executeMutations(DGRAPH_CONNECTION, mutation)

  return response.Uids
}
```

### Define Dgraph schema

While Dgraph can be used without defining a schema, in order to use the vector
search functionality of Dgraph we must declare a schema in order to create an
index on the `Product.embedding` property.

To define your Dgraph schema with vector indexing support we add the
`@index(hnsw)` directive to the property storing the embedding value, in this
case `Product.embedding`. We also define the other property types and node
labels.

```rdf
<Category.name>: string @index(hash) .
<Product.category>: uid @reverse .
<Product.description>: string .
<Product.id>: string @index(hash) .
<Product.embedding>: float32vector @index(hnsw) .
```

To apply this schema to our Dgraph instance we can make a POST request to the
`/alter` endpoint of our Dgraph instance:

```bash
curl -X POST localhost:8080/alter --silent --data-binary '@dqlschema.txt'
```

or use the schema tab of the Ratel interface to apply the schema.

### Query Modus endpoint

```graphql
TODO: GraphQL query
```

### Resources

- Video: https://www.youtube.com/watch?v=Z2fB-nBf4Wo
- Code: https://github.com/hypermodeinc/modus-recipes/tree/main/dgraph-101

## Natural language search with Modus Collections

The Modus Collections API provides a robust way to store, retrieve, and search
through data using both natural language and vector-based search methods.

### Understanding key components

**Collections**: a collection is a structured storage that organizes and stores
textual data and associated metadata. Collections enable sophisticated search,
retrieval, and classification tasks using vector embeddings.

**Search Methods**: a search method associated with a collection, defines how to
convert collection items into a vector representation and provides indexing
parameters.

**Vector embeddings**: for vector-based search and comparison, Modus converts
each item in the collection into a vector representation called **embedding**.
By embedding data, you enable powerful natural language and similarity-based
searches.

<Note>
  Modus runtime automatically compute the embeddings, according to your
  configuration, when you add or update items.
</Note>

### Initializing your collection

Before implementing search, ensure you have
[defined a collection in the app manifest](./app-manifest#collections). In this
example, `myProducts` is the collection used to store product descriptions.

First, we need to populate the collection with items (for example, product
descriptions). You can insert individual or multiple items using the `upsert`
and `upsertBatch` methods, respectively.

Use `upsert` to insert a product description into the collection. If you don't
specify a key, Modus generates a unique key for you.

<CodeGroup>

```go Go
func AddProduct(description string) ([]string, error) {
  res, err := collections.Upsert(
    "myProducts",  // Collection name defined in the manifest
    nil,           // using nil to let Modus generate a unique ID
    description,   // the text to store
    nil            // we don't have labels for this item
    )
  if err != nil {
    return nil, err
  }
  return res.Keys, nil
}
```

```ts AssemblyScript
export function addProduct(description: string): string {
  const response = collections.upsert(
    "myProducts", // Collection name defined in the manifest
    null, // using null to let Modus generate a unique ID
    description, // the text to store
    // no labels for this item
    // no namespace provided, use defautl namespace
  )
  return response.keys[0] // return the identifier of the item
}
```

</CodeGroup>

### Configure your search method

The search capability relies on a search method and embedding function. To
configure your search method.

#### Create an embedding function

An embedding function is any API function that transforms text into vectors that
represent their meaning in a high-dimensional space.

Embeddings functions must have the following signature:

<CodeGroup>

```go Go
package main

func Embed(text []string) ([][]float32, error) {
  ...
}

```

```ts AssemblyScript
export function embed(text: string[]): f32[][] {
  ...
}
```

</CodeGroup>

Modus computes vectors using embedding models. Here are a few examples:

<Tabs>
  <Tab title="all-MiniLM-L6-v2">

[Declare the model](./app-manifest#models) in the app manifest

```json model.json
  "models": {
    // model card: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
    "minilm": {
      "sourceModel": "sentence-transformers/all-MiniLM-L6-v2", // model name on the provider
      "provider": "hugging-face", // provider for this model
      "connection": "hypermode" // host where the model is running
    }
  }
```

Create the embedding function using the embedding model:

<CodeGroup>

```go Go
package main

import (
"github.com/hypermodeAI/functions-go/pkg/models"
"github.com/hypermodeAI/functions-go/pkg/models/experimental"
)

func Embed(text []string) ([][]float32, error) {
  // "minilm" is the model name declared in the application manifest
  model, err := models.GetModel[experimental.EmbeddingsModel]("minilm")
  if err != nil {
      return nil, err
  }

  input, err := model.CreateInput(text...)
  if err != nil {
      return nil, err
  }
  output, err := model.Invoke(input)
  if err != nil {
      return nil, err
  }
  return output.Predictions, nil
}

```

```ts AssemblyScript
import { models } from "@hypermode/modus-sdk-as"
import { EmbeddingsModel } from "@hypermode/modus-sdk-as/models/experimental/embeddings"

export function embed(texts: string[]): f32[][] {
  // "minilm" is the model name declared in the application manifest
  const model = models.getModel<EmbeddingsModel>("minilm")
  const input = model.createInput(texts)
  const output = model.invoke(input)
  return output.predictions
}
```

</CodeGroup>
  </Tab>
  <Tab title="OpenAI">
    [Declare the model](./app-manifest#models) in the app manifest

```json modus.json
  "models": {
    // model docs: https://platform.openai.com/docs/models/embeddings
    "openai-embeddings": {
      "sourceModel": "text-embedding-3-small",
      "connection": "openai",
      "path": "v1/embeddings"
    }
  },
  "connections": {
    "openai": {
      "type": "http",
      "baseUrl": "https://api.openai.com/",
      "headers": {
        "Authorization": "Bearer {{API_KEY}}"
      }
    }
  }
```

Create the embedding function using the embedding model:

<CodeGroup>

```go Go
import (
  "github.com/hypermodeAI/functions-go/pkg/models"
  "github.com/hypermodeAI/functions-go/pkg/models/experimental"
)

func Embed(texts ...string) ([][]float32, error) {
  // retrieve the model for OpenAI embeddings
  // "openai-embeddings" is the model name declared in the app manifest
  model, err := models.GetModel[openai.EmbeddingsModel]("openai-embeddings")
  if err != nil {
    return nil, fmt.Errorf("failed to get OpenAI embeddings model: %w", err)
  }

  // create input for the model using the provided texts
  input, err := model.CreateInput(texts)
  if err != nil {
    return nil, fmt.Errorf("failed to create input for OpenAI embeddings: %w", err)
  }

  // invoke the model with the generated input
  output, err := model.Invoke(input)
  if err != nil {
    return nil, fmt.Errorf("failed to invoke OpenAI embeddings model: %w", err)
  }

  // prepare the result slice based on the size of the output data
  results := make([][]float32, len(output.Data))

  // copy embeddings from output into the result slice
  for i, d := range output.Data {
    results[i] = d.Embedding
  }

  return results, nil
}
```

```ts AssemblyScript
export function embed(text: string[]): f32[][] {
  const model = models.getModel<OpenAIEmbeddingsModel>("openai-embeddings")
  // "openai-embeddings" is the model name declared in the app manifest
  const input = model.createInput(text)
  const output = model.invoke(input)
  return output.data.map<f32[]>((d) => d.embedding)
}
```

</CodeGroup>
  </Tab>
</Tabs>

#### Declare the search method

With an embedding function in place, declare a search method in the
[collection properties](/modus/app-manifest#collections).

```json modus.json
  "collections": {
    "myProducts": {
        "searchMethods": {
            "searchMethod1": {
                "embedder": "embed" // embedding function name
            }
        }
    }
  }

```

### Implement semantic similarity search

With the products stored, you can now search the collection by semantic
similarity. The search] API computes an embedding for the provided text,
compares it with the embeddings of the items in the collection, and returns the
most similar items.

<CodeGroup>

```go Go
func SearchProducts(productDescription string, maxItems int) (*collections.CollectionSearchResult, error) {
  return collections.Search(myProducts, searchMethods[0], productDescription, collections.WithLimit(maxItems), collections.WithReturnText(true))
}
```

```ts AssemblyScript
export function searchProducts(
  product_description: string,
  maxItems: i32,
): collections.CollectionSearchResult {
  const response = collections.search(
    "myProducts", // collection name declared in the application manifest
    "searchMethod1", // search method declared for this collection in the manifest
    product_description, // text to search for
    maxItems,
    true, //  returnText: bool, true to return the items text.
    // no namespace provide, use the default namespace
  )
  return response
}
```

</CodeGroup>

#### Search result format

The search response is a CollectionSearchResult containing the following fields:

- `collection`: the name of the collection.
- `status`: the status of the operation.
- `objects`: the search result items with their text, distance, and score
  values.
  - `distance`: a lower value indicates a closer match between the search query
    and the item in the collection
  - `score`: a higher value (closer to 1) represents a better match

```json
{
  "collection": "myProducts",
  "status": "success",
  "objects": [
    {
      "key": "item-key-123",
      "text": "Sample product description",
      "distance": 0.05,
      "score": 0.95
    }
  ]
}
```

### Search for similar Items

When you need to search similar items to a given item, use the `searchByVector`
API. Retrieve the vector associated with the given item by its key, then perform
a search using that vector.

<CodeGroup>

```go Go
func SearchSimilarProduct(productKey string, maxItems int) (*collections.CollectionSearchResult, error) {
  vec, err := collections.GetVector(
    "myProducts",
    "searchMethod1",
    productKey)

  if err != nil {
    return nil, err
  }
  return collections.SearchByVector(
    "myProducts",
    "searchMethod1",
    vec,
    collections.WithLimit(maxItems),
    collections.WithReturnText(true)
  )
}
```

```ts AssemblyScript
export function searchSimilarProducts(
  productId: string,
  maxItems: i32,
): collections.CollectionSearchResult {
  const embedding_vector = collections.getVector(
    "myProducts", // Collection name defined in the manifest
    "searchMethod1", // search method declared for the collection
    productId, // key of the collection item to retrieve
  )
  // search for similar products using the embedding vector
  const response = collections.searchByVector(
    "myProducts",
    "searchMethod1",
    embedding_vector,
    maxItems,
    true, // get the product description
  )

  return response
}
```

</CodeGroup>

### Develop locally with Collections

While Collections expose a key-value interface for working with data, a
PostgreSQL database instance persists the data. When using Collections in a
Modus app deployed to the Hypermode platform, Hypermode manages this PostgreSQL
database and users don't need to perform any additional setup. However, when
developing with Modus locally or outside of the Hypermode platform, you need a
PostgreSQL instance for the Collections persistence layer.

<Note>
  The dependency on PostgreSQL is temporary and we're working to replace it with
  ModusDB, an embedded multi-model database, in an upcoming release.
</Note>

Any hosting method for this PostgreSQL database is sufficient, so feel free to
use your favorite method of installing and running PostgreSQL locally or in the
cloud. You must apply a database migration after you start the PostgreSQL
database (Step 3 below) and set the `MODUS_DB` environment variable with your
PostgreSQL database connection string (Step 4 below). The steps below describe
using [Docker](https://www.docker.com/products/docker-desktop/) to start and
configure a PostgreSQL instance for local development with Collections.

To start and configure a local PostgreSQL instance for working with Collections
locally using [Docker Compose](https://docs.docker.com/compose/), follow these
steps:

<Steps>

  <Step title="Clone Modus locally">
  Clone the [Modus GitHub repository](https://github.com/hypermodeinc/modus):

```sh
git clone https://github.com/hypermodeinc/modus.git
```

  </Step>

  <Step title="Start a PostgreSQL instance">

Start the Collections PostgreSQL database using the local Docker Compose script:

```sh
cd modus/runtime/tools/local
docker compose up
```

  </Step>

  <Step title="Apply database migration">

Next, apply the database schema using the
[golang-migrate](https://github.com/golang-migrate/migrate) utility.

On MacOS, you can install this utility with the following:

```sh
brew install golang-migrate
```

Then, you can apply the migration as follows:

```sh
export POSTGRESQL_URL='postgresql://postgres:postgres@localhost:5433/my-runtime-db?sslmode=disable'
migrate -database ${POSTGRESQL_URL} -path ../../db/migrations up
```

  </Step>

  <Step title="Set environment variable">
  Set the `MODUS_DB` environment variable:

```sh
export MODUS_DB=postgresql://postgres:postgres@localhost:5433/my-runtime-db?sslmode=disable
```

  </Step>
</Steps>

You can now use Collections locally in your Modus app.
